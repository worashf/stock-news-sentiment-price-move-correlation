{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-30T18:55:54.978613Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "\n",
    "try:\n",
    "    from src import load_csv_finantial_data\n",
    "except ImportError:\n",
    "    print(\"Warning: Could not import 'load_csv_finantial_data' from src.\")\n",
    "    print(\"Please ensure '../../src' is the correct path and 'load_csv_finantial_data' exists.\")\n",
    "    print(\"Falling back to a placeholder function for demonstration purposes.\")\n",
    "    def load_csv_finantial_data(path):\n",
    "        print(f\"Attempting to load data from: {path} with a placeholder loader.\")\n",
    "        try:\n",
    "\n",
    "            df = pd.read_csv(path)\n",
    "            if 'headline' not in df.columns:\n",
    "                raise ValueError(\"CSV must contain a 'headline' column.\")\n",
    "\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file {path} was not found.\")\n",
    "            print(\"Please ensure the data_path variable is set correctly.\")\n",
    "            sys.exit(1)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading the data: {e}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append('../../src')\n",
    "\n",
    "\n",
    "# Download necessary NLTK data\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('stopwords')\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "# Initialize sentiment analyzers\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Download and load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy model 'en_core_web_sm'...\")\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define data path\n",
    "data_path = '../../data/news/raw_analyst_ratings.csv'\n",
    "\n",
    "# Load data using the (potentially placeholder) function\n",
    "stock_news = load_csv_finantial_data(data_path)\n",
    "\n",
    "# --- Functions from original script ---\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Basic text preprocessing\"\"\"\n",
    "    text = str(text).lower()\n",
    "    return text\n",
    "\n",
    "def get_vader_sentiment(text):\n",
    "    return sia.polarity_scores(text)\n",
    "\n",
    "def get_textblob_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return {\n",
    "        'polarity': analysis.sentiment.polarity,\n",
    "        'subjectivity': analysis.sentiment.subjectivity\n",
    "    }\n",
    "\n",
    "# --- Apply preprocessing and initial sentiment analysis\n",
    "stock_news['cleaned_headline'] = stock_news['headline'].apply(preprocess_text)\n",
    "stock_news['vader_sentiment'] = stock_news['cleaned_headline'].apply(get_vader_sentiment)\n",
    "stock_news['textblob_sentiment'] = stock_news['cleaned_headline'].apply(get_textblob_sentiment)\n",
    "\n",
    "# Extract sentiment scores to separate columns\n",
    "stock_news['vader_compound'] = stock_news['vader_sentiment'].apply(lambda x: x['compound'])\n",
    "stock_news['vader_neg'] = stock_news['vader_sentiment'].apply(lambda x: x['neg'])\n",
    "stock_news['vader_neu'] = stock_news['vader_sentiment'].apply(lambda x: x['neu'])\n",
    "stock_news['vader_pos'] = stock_news['vader_sentiment'].apply(lambda x: x['pos'])\n",
    "stock_news['textblob_polarity'] = stock_news['textblob_sentiment'].apply(lambda x: x['polarity'])\n",
    "stock_news['textblob_subjectivity'] = stock_news['textblob_sentiment'].apply(lambda x: x['subjectivity'])\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nDisplaying initial sentiment distributions...\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "sns.histplot(stock_news['vader_compound'], bins=30, ax=axes[0, 0], kde=True)\n",
    "axes[0, 0].set_title('VADER Compound Sentiment Distribution')\n",
    "sns.histplot(stock_news['textblob_polarity'], bins=30, ax=axes[0, 1], kde=True)\n",
    "axes[0, 1].set_title('TextBlob Polarity Distribution')\n",
    "sns.histplot(stock_news['vader_pos'], bins=30, ax=axes[1, 0], kde=True)\n",
    "axes[1, 0].set_title('VADER Positive Sentiment Distribution')\n",
    "sns.histplot(stock_news['vader_neg'], bins=30, ax=axes[1, 1], kde=True)\n",
    "axes[1, 1].set_title('VADER Negative Sentiment Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Sentiment by publisher\n",
    "if 'publisher' in stock_news.columns:\n",
    "    publisher_sentiment = stock_news.groupby('publisher').agg(\n",
    "        vader_compound_mean=('vader_compound', 'mean'),\n",
    "        textblob_polarity_mean=('textblob_polarity', 'mean'),\n",
    "        headline_count=('headline', 'count')\n",
    "    ).sort_values('headline_count', ascending=False)\n",
    "    print(\"\\nSentiment by Publisher (Top 10 by headline count):\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(publisher_sentiment.head(10))\n",
    "    except ImportError:\n",
    "        print(publisher_sentiment.head(10))\n",
    "else:\n",
    "    print(\"\\n'publisher' column not found. Skipping sentiment by publisher analysis.\")\n",
    "\n",
    "\n",
    "# Sentiment by stock\n",
    "if 'stock' in stock_news.columns:\n",
    "    stock_sentiment_orig = stock_news.groupby('stock').agg(\n",
    "        vader_compound_mean=('vader_compound', 'mean'),\n",
    "        textblob_polarity_mean=('textblob_polarity', 'mean'),\n",
    "        headline_count=('headline', 'count')\n",
    "    ).sort_values('headline_count', ascending=False)\n",
    "    print(\"\\nSentiment by Stock (Top 10 by headline count - Original Method):\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(stock_sentiment_orig.head(10))\n",
    "    except ImportError:\n",
    "        print(stock_sentiment_orig.head(10))\n",
    "else:\n",
    "    print(\"\\n'stock' column not found. Skipping original sentiment by stock analysis.\")\n",
    "\n",
    "\n",
    "# Word cloud for most common words\n",
    "positive_text_wc = ' '.join(stock_news[stock_news['vader_compound'] > 0.5]['cleaned_headline'])\n",
    "negative_text_wc = ' '.join(stock_news[stock_news['vader_compound'] < -0.5]['cleaned_headline'])\n",
    "\n",
    "fig_wc, axes_wc = plt.subplots(1, 2, figsize=(16, 8))\n",
    "if positive_text_wc.strip():\n",
    "    wordcloud_pos = WordCloud(width=600, height=400, background_color='white').generate(positive_text_wc)\n",
    "    axes_wc[0].imshow(wordcloud_pos, interpolation='bilinear')\n",
    "    axes_wc[0].set_title('Common Words in Strongly Positive Headlines (VADER > 0.5)')\n",
    "else:\n",
    "    axes_wc[0].text(0.5, 0.5, 'No strongly positive headlines found for word cloud.',\n",
    "                    horizontalalignment='center', verticalalignment='center', transform=axes_wc[0].transAxes)\n",
    "axes_wc[0].axis('off')\n",
    "\n",
    "if negative_text_wc.strip():\n",
    "    wordcloud_neg = WordCloud(width=600, height=400, background_color='white').generate(negative_text_wc)\n",
    "    axes_wc[1].imshow(wordcloud_neg, interpolation='bilinear')\n",
    "    axes_wc[1].set_title('Common Words in Strongly Negative Headlines (VADER < -0.5)')\n",
    "else:\n",
    "    axes_wc[1].text(0.5, 0.5, 'No strongly negative headlines found for word cloud.',\n",
    "                    horizontalalignment='center', verticalalignment='center', transform=axes_wc[1].transAxes)\n",
    "axes_wc[1].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Define sentiment_class based on VADER compound score (CRITICAL STEP FOR NEW FEATURES)\n",
    "# Thresholds for VADER: positive > 0.05, negative < -0.05, neutral otherwise\n",
    "conditions = [\n",
    "    (stock_news['vader_compound'] > 0.05),\n",
    "    (stock_news['vader_compound'] < -0.05)\n",
    "]\n",
    "choices = ['positive', 'negative']\n",
    "stock_news['sentiment_class'] = np.select(conditions, choices, default='neutral')\n",
    "print(f\"\\n'sentiment_class' column created. Value counts:\\n{stock_news['sentiment_class'].value_counts()}\")\n",
    "\n",
    "\n",
    "# 1. Create binary sentiment flags\n",
    "stock_news['is_positive'] = (stock_news['sentiment_class'] == 'positive').astype(int)\n",
    "stock_news['is_negative'] = (stock_news['sentiment_class'] == 'negative').astype(int)\n",
    "stock_news['is_neutral'] = (stock_news['sentiment_class'] == 'neutral').astype(int)\n",
    "print(\"\\nBinary sentiment flags (is_positive, is_negative, is_neutral) created.\")\n",
    "\n",
    "# 2. Enhanced Sentiment Analysis Features\n",
    "stock_news['sentiment_intensity'] = stock_news['vader_compound'].abs()\n",
    "stock_news['strong_positive'] = ((stock_news['vader_compound'] > 0.5) &\n",
    "                                 (stock_news['textblob_polarity'] > 0.3)).astype(int)\n",
    "stock_news['strong_negative'] = ((stock_news['vader_compound'] < -0.5) &\n",
    "                                 (stock_news['textblob_polarity'] < -0.3)).astype(int)\n",
    "print(\"\\nEnhanced sentiment features (sentiment_intensity, strong_positive, strong_negative) created.\")\n",
    "\n",
    "# 3. Sentiment Distribution Dashboard\n",
    "print(\"\\nDisplaying Sentiment Distribution Dashboard...\")\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Distribution Plot\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(data=stock_news, x='vader_compound', hue='sentiment_class',\n",
    "             palette={'negative':'red', 'neutral':'gray', 'positive':'green'},\n",
    "             bins=30, kde=True)\n",
    "plt.title('Sentiment Score Distribution by Class (VADER)')\n",
    "plt.axvline(-0.05, color='red', linestyle='--', alpha=0.5, label='Negative Threshold')\n",
    "plt.axvline(0.05, color='green', linestyle='--', alpha=0.5, label='Positive Threshold')\n",
    "plt.legend()\n",
    "\n",
    "# Proportion Plot\n",
    "plt.subplot(2, 2, 2)\n",
    "sentiment_proportions = stock_news['sentiment_class'].value_counts(normalize=True).sort_index()\n",
    "\n",
    "defined_colors = {'negative':'red', 'neutral':'gray', 'positive':'green'}\n",
    "pie_colors = [defined_colors[s_class] for s_class in sentiment_proportions.index if s_class in defined_colors]\n",
    "pie_explode = [0.05 if s_class in ['positive', 'negative'] else 0 for s_class in sentiment_proportions.index]\n",
    "\n",
    "sentiment_proportions.plot(kind='pie', autopct='%1.1f%%',\n",
    "                           colors=pie_colors,\n",
    "                           explode=pie_explode)\n",
    "plt.title('Sentiment Proportions')\n",
    "plt.ylabel('')\n",
    "\n",
    "# Intensity Analysis\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(data=stock_news, x='sentiment_class', y='sentiment_intensity',\n",
    "            hue='sentiment_class',\n",
    "            order=['negative', 'neutral', 'positive'],\n",
    "            palette={'negative':'red', 'neutral':'gray', 'positive':'green'},\n",
    "            legend=False)\n",
    "plt.title('Sentiment Intensity by Class (Absolute VADER Score)')\n",
    "plt.xlabel('Sentiment Class')\n",
    "plt.ylabel('Intensity (Absolute Score)')\n",
    "\n",
    "# TextBlob Comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(data=stock_news, x='vader_compound', y='textblob_polarity',\n",
    "                hue='sentiment_class', palette={'negative':'red', 'neutral':'gray', 'positive':'green'},\n",
    "                hue_order=['negative', 'neutral', 'positive'],\n",
    "                alpha=0.6)\n",
    "plt.title('VADER vs TextBlob Alignment, Colored by VADER-based Class')\n",
    "plt.xlabel('VADER Compound Score')\n",
    "plt.ylabel('TextBlob Polarity')\n",
    "plt.axvline(0, color='black', linestyle=':')\n",
    "plt.axhline(0, color='black', linestyle=':')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Temporal Sentiment Trends\n",
    "if 'date' in stock_news.columns:\n",
    "    print(\"\\nAnalyzing temporal sentiment trends...\")\n",
    "    try:\n",
    "        # Attempt to convert to datetime, handling potential errors\n",
    "        stock_news['date'] = pd.to_datetime(stock_news['date'], errors='coerce')\n",
    "        # Drop rows where date conversion failed\n",
    "        stock_news.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "        if not stock_news.empty:\n",
    "            stock_news['month_period'] = stock_news['date'].dt.to_period('M')\n",
    "\n",
    "            monthly_sentiment = stock_news.groupby('month_period')[\n",
    "                ['is_positive', 'is_negative', 'is_neutral']\n",
    "            ].mean().mul(100)\n",
    "\n",
    "            if not monthly_sentiment.empty:\n",
    "                plt.figure(figsize=(14, 7))\n",
    "                monthly_sentiment.plot(kind='line', style=['g-^', 'r-s', 'k--o'], linewidth=2)\n",
    "                plt.title('Monthly Sentiment Trends (%)')\n",
    "                plt.ylabel('Percentage of Headlines')\n",
    "                plt.xlabel('Month')\n",
    "                plt.legend(['Positive', 'Negative', 'Neutral'])\n",
    "                plt.grid(True, alpha=0.4)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"No data available for monthly sentiment trends after processing.\")\n",
    "        else:\n",
    "            print(\"No valid date entries found to analyze temporal trends.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not analyze temporal trends: {e}\")\n",
    "else:\n",
    "    print(\"\\n'date' column not found. Skipping temporal sentiment trends analysis.\")\n",
    "\n",
    "\n",
    "# 5. Sentiment by Stock Analysis\n",
    "if 'stock' in stock_news.columns:\n",
    "    print(\"\\nAnalyzing sentiment for top 10 most mentioned stocks...\")\n",
    "    top_stocks_count = stock_news['stock'].value_counts()\n",
    "    if not top_stocks_count.empty:\n",
    "        top_stocks = top_stocks_count.head(10).index\n",
    "        stock_sentiment_enhanced = stock_news[stock_news['stock'].isin(top_stocks)].groupby('stock')[\n",
    "            ['is_positive', 'is_negative', 'is_neutral']\n",
    "        ].mean().sort_values('is_positive', ascending=False) # Proportions\n",
    "\n",
    "        if not stock_sentiment_enhanced.empty:\n",
    "            stock_sentiment_enhanced.plot(kind='barh', stacked=True,\n",
    "                                          color=['green', 'red', 'gray'], # Positive, Negative, Neutral\n",
    "                                          figsize=(12, 8))\n",
    "            plt.title('Sentiment Distribution for Top 10 Most Mentioned Stocks')\n",
    "            plt.xlabel('Proportion of Headlines')\n",
    "            plt.ylabel('Stock Symbol')\n",
    "            plt.legend(['Positive', 'Negative', 'Neutral'], bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No data available for enhanced stock sentiment analysis.\")\n",
    "    else:\n",
    "        print(\"No stock data to analyze for top 10.\")\n",
    "else:\n",
    "    print(\"\\n'stock' column not found. Skipping enhanced sentiment by stock analysis.\")\n",
    "\n",
    "\n",
    "# 6. Sentiment Lexicon Analysis\n",
    "print(\"\\nPerforming Sentiment Lexicon Analysis...\")\n",
    "def get_sentiment_words(text, sentiment_type, threshold=0.5):\n",
    "    doc = nlp(str(text))\n",
    "    words = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct and token.text.isalpha():\n",
    "            score = sia.polarity_scores(token.text)['compound']\n",
    "            if sentiment_type == 'positive' and score >= threshold:\n",
    "                words.append(token.text)\n",
    "            elif sentiment_type == 'negative' and score <= -threshold:\n",
    "                words.append(token.text)\n",
    "    return words\n",
    "\n",
    "positive_words_lexicon = Counter()\n",
    "negative_words_lexicon = Counter()\n",
    "\n",
    "# Iterate safely, checking if 'cleaned_headline' exists and is not NaN\n",
    "if 'cleaned_headline' in stock_news.columns:\n",
    "    for _, row in stock_news.iterrows():\n",
    "        headline_text = row['cleaned_headline']\n",
    "        if pd.notna(headline_text):\n",
    "            if row['is_positive']:\n",
    "                positive_words_lexicon.update(get_sentiment_words(headline_text, 'positive'))\n",
    "            elif row['is_negative']:\n",
    "                negative_words_lexicon.update(get_sentiment_words(headline_text, 'negative'))\n",
    "\n",
    "    print(\"\\nTop 10 Positive Words (from lexicon analysis):\")\n",
    "    for word, count in positive_words_lexicon.most_common(10):\n",
    "        print(f\"- {word}: {count}\")\n",
    "\n",
    "    print(\"\\nTop 10 Negative Words (from lexicon analysis):\")\n",
    "    for word, count in negative_words_lexicon.most_common(10):\n",
    "        print(f\"- {word}: {count}\")\n",
    "else:\n",
    "    print(\"'cleaned_headline' column not found. Skipping lexicon analysis.\")\n",
    "\n",
    "\n",
    "# 7. Save Enhanced Dataset\n",
    "output_path = '../../data/news/enhanced_analyst_ratings.csv'\n",
    "try:\n",
    "    stock_news.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSuccessfully saved enhanced dataset with sentiment features to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError saving dataset to {output_path}: {e}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "DataFrame shape: (1407328, 6)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6972f7b3b33d9570"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
